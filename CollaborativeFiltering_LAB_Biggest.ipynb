{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc.stop()\n",
    "#from pyspark import SparkContext \n",
    "#sc = SparkContext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numPartitions = 10\n",
    "baseDir = os.path.join('hdfs://ns372208.ip-91-121-199.eu/extract')\n",
    "TwoMonthFilename = os.path.join(baseDir, 'extract_multimedia.tsv')\n",
    "\n",
    "rawRatings = sc.textFile(TwoMonthFilename).repartition(numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs = rawRatings.map(lambda line: line.split('\\t'))\n",
    "logs = logs.filter(lambda x : len(x) == 8) # filter not completed rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ProductList = (logs\n",
    "               .map(lambda x:(x[6],1))\n",
    "               .reduceByKey(lambda x,y : x+y, numPartitions=15)\n",
    "               .keys()\n",
    "               .collect()\n",
    "               )\n",
    "\n",
    "\n",
    "products_ints = dict()\n",
    "ints_products = dict()\n",
    "\n",
    "# iterate over all products labelled and mapping with a int rather \n",
    "i = 1\n",
    "for product in ProductList:\n",
    "    products_ints[product] = i\n",
    "    ints_products[i] = product   \n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "UserList =  (logs\n",
    "             .map(lambda x:(x[0],1))\n",
    "             .reduceByKey(lambda x,y : x+y, numPartitions=15)\n",
    "             .keys()\n",
    "             .collect()\n",
    "            )\n",
    "\n",
    "users_ints = dict()\n",
    "ints_users = dict()\n",
    "\n",
    "# iterate over all user hexa id and mapping with a int rather\n",
    "i = 1\n",
    "for user in UserList:\n",
    "    users_ints[user] = i\n",
    "    ints_users[i] = user   \n",
    "    i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs = logs.map(lambda x:(users_ints[x[0]],x[1],x[2],x[3],x[4],x[5], products_ints[x[6]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1434403,\n",
       "  u'5578b13d0cf28db65d6eed5d',\n",
       "  u'Wed Jun 10 2015 23:50:42 GMT+0200 (CEST)',\n",
       "  u'2500',\n",
       "  u'10',\n",
       "  u'access offer page',\n",
       "  332)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print logs.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">SEPARATION LOGS RASSEMBLES PAR TYPE</span> #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(596701, u'5578b1800cf28db65d6eee12', u'Wed Jun 10 2015 23:51:52 GMT+0200 (CEST)', u'0', u'3', u'add to cart', 1682), (1011603, u'561cb6d50cf258e83bc071a7', u'Tue Oct 13 2015 09:47:00 GMT+0200 (CEST)', u'0', u'6', u'remove from cart', 3543), (453372, u'561cb7630cf2fe9257a4c37a', u'Tue Oct 13 2015 09:49:10 GMT+0200 (CEST)', u'0', u'3', u'add to cart', 3543)]\n",
      "[(688212, u'5578b16a0cf21c4200d0007d', u'Wed Jun 10 2015 23:50:53 GMT+0200 (CEST)', u'33514', u'10', u'access offer page', 1682), (1338275, u'564d8ab20cf2ed3701e96551', u'Thu Nov 19 2015 09:39:14 GMT+0100 (CET)', u'4699', u'10', u'access offer page', 3118), (559153, u'561cb6e10cf2fe9257a4c216', u'Tue Oct 13 2015 09:46:41 GMT+0200 (CEST)', u'42329', u'10', u'access offer page', 145)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cartLogs = (logs \n",
    "            .filter(lambda x : x[5] in ('remove from cart','add to cart'))\n",
    "           )\n",
    "accessOfferLogs = (logs \n",
    "            .filter(lambda x : x[5] in ('access offer page'))\n",
    "            .filter(lambda x : x[3] != '0')\n",
    "           )\n",
    "#oddLogs = (logs \n",
    "#            .filter(lambda x : x[5] in ('userActionLabel'))\n",
    "#           )\n",
    "\n",
    "print cartLogs.take(3)\n",
    "print accessOfferLogs.take(3)\n",
    "#print oddLogs.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> SUPRESSION DES ACCESS LOGS UNIQUES PAR USER </span>#\n",
    "### Le collaborative filtering algorithm n'est pas capable de prédire des ratings à froid ###\n",
    "#### (Préférer plutôt un modele baseline pour le cold start ou pour les users non identifiés) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onlyOneAccessOfferLogs = (accessOfferLogs\n",
    "                                 .map(lambda x : ((x[0],x[6]),1))\n",
    "                                 .reduceByKey(lambda x,y : x+y, numPartitions=15)\n",
    "                                 .map(lambda ((x,y),z): (x,1))\n",
    "                                 .reduceByKey(lambda x,y : x+y, numPartitions=22)\n",
    "                                 .filter(lambda (x,y) : y==1)\n",
    "                                 .map(lambda (x,y): (x,-1))\n",
    "                                 )\n",
    "\n",
    "# The list could be huge, so we broadcast it through the cluster \n",
    "# Other optimisation clue : Translate User Id into integers ..... \n",
    "\n",
    "#319493\n",
    "#629127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print onlyOneAccessOfferLogs.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(361242, u'55a6d9d30cf21d087544dc06', u'Thu Jul 16 2015 00:08:19 GMT+0200 (CEST)', u'23732', u'10', u'access offer page', 2896)]\n"
     ]
    }
   ],
   "source": [
    "print accessOfferLogs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accessOfferLogs2 = (accessOfferLogs\n",
    "                   .map(lambda x : (x[0],(x[1],x[2],x[3],x[4],x[5],x[6])))\n",
    "                   .leftOuterJoin(onlyOneAccessOfferLogs, numPartitions=30)\n",
    "                   .filter(lambda (x,y): y[1] != -1 )\n",
    "                   .map(lambda (x,y) : (x,y[0][0],y[0][1],y[0][2],y[0][3],y[0][4],y[0][5]))\n",
    "                   #.take(1)\n",
    "                   )\n",
    "#print accessOfferLogs.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print accessOfferLogs2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#accessOfferLogs.saveAsTextFile('hdfs://ns372208.ip-91-121-199.eu/extract/extract08-08_10-08_onlyAccessOfferLogsFILTERED.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print accessOfferLogs.filter(lambda x : x[3]== '0').count()\n",
    "print accessOfferLogs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion des \"NaN values\" ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def returnMeANumber(string):\n",
    "    if string.isdigit():\n",
    "        return int(string)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cases ###\n",
    "* #### 'access offer page' / duration : 0  ===> Pas d'action spécifiques donc interet très faible ####\n",
    "* #### 'add to cart' / duration = 0 toujours ===> Interet fort ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############ TIME & DATE Labo ##########################################\n",
    "import time\n",
    "x = 'Sat Sep 19 2015 10:15:10 GMT+0200 (CEST)'\n",
    "y = 'Sat Sep 19 2015 10:15:09 GMT+0200 (CEST)'\n",
    "print x[:-16]\n",
    "print time.strptime(x[:-16],\"%a %b %d %Y %H:%M:%S\") > time.strptime(y[:-16],\"%a %b %d %Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def agregOneProductCartActions(x,y):\n",
    "    print x\n",
    "    xTimeString = x[0]\n",
    "    yTimeString = y[0]\n",
    "    xTime = time.strptime(xTimeString[:-16], \"%a %b %d %Y %H:%M:%S\")\n",
    "    yTime = time.strptime(yTimeString[:-16], \"%a %b %d %Y %H:%M:%S\")\n",
    "    returnTime = xTimeString if xTime > yTime else yTimeString\n",
    "    return (returnTime, 0, x[2]+y[2])\n",
    "\n",
    "def agregOneProductAccessOfferActions(x,y):\n",
    "    print x\n",
    "    xTimeString = x[0]\n",
    "    yTimeString = y[0]\n",
    "    xTime = time.strptime(xTimeString[:-16], \"%a %b %d %Y %H:%M:%S\")\n",
    "    yTime = time.strptime(yTimeString[:-16], \"%a %b %d %Y %H:%M:%S\")\n",
    "    returnTime = xTimeString if xTime > yTime else yTimeString\n",
    "    return (returnTime, x[1]+y[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aggregCartLogs = (cartLogs\n",
    "                  .map(lambda (a,b,c,d,e,f,g) : ((a,g),(c,d,1)) if f == 'add to cart' else ((a,g),(c,d,-1)))\n",
    "                  .reduceByKey(agregOneProductCartActions)\n",
    "                  )\n",
    "aggregCartLogs.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies pour les actions de type \"CART\" ##\n",
    "#### logiquement, après agréggation des 'add' (+1) et 'remove' (-1), l'on ne devrait PAS avoir de valeurs négatives dans le décompte pour le couple (utilisateur, produit). ####\n",
    "##### Hypothéses : #####\n",
    "* ##### Certaines valeurs négatives peuvent être expliquées par l'absence des précédentes 'add' actions puisque loggé juste avant la begin date du fichier de logs considéré  ###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print aggregCartLogs.map(lambda x : x[1][2]).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ReadyCartLogs = aggregCartLogs.map(lambda ((k1,k2),(x,y,z)) : ((k1,k2),4.0) if z > 0 else ((k1,k2),2.0) ).cache()\n",
    "\n",
    "ReadyCartLogs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print accessOfferLogs.count()\n",
    "aggregAccessOfferLogs = (accessOfferLogs\n",
    "                  .map(lambda (a,b,c,d,e,f,g) : ((a,g),(c,returnMeANumber(d))))\n",
    "                  .reduceByKey(agregOneProductAccessOfferActions)\n",
    "                  )\n",
    "\n",
    "aggregAccessOfferLogs.take(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## <span style=\"color:red\">Managing extreme values : assigning a cap value </span>##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print aggregAccessOfferLogs.filter(lambda x : int(x[1][1])>150000).count() \n",
    "logs_in_ms = aggregAccessOfferLogs.filter(lambda x : int(x[1][1])>100000).map(lambda x : int(x[1][1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "print \"Min : %d\" %(min(logs_in_ms))\n",
    "print \"Max : %d\" %(max(logs_in_ms))\n",
    "\n",
    "\n",
    "plt.hist(logs_in_ms,range=[90000, 500000])\n",
    "plt.title(\"Logs in ms\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning a cap calue of 150.000 for all above extreme values ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extremeCappedAggregAccessOfferLogs = aggregAccessOfferLogs.map(lambda x : ((x[0][0],x[0][1]),(x[1][0],100000)) if int(x[1][1])>100000 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################### Prends beaucoup de temps ######################\n",
    "mean = extremeCappedAggregAccessOfferLogs.map(lambda x : int(x[1][1])).mean()\n",
    "std = extremeCappedAggregAccessOfferLogs.map(lambda x : int(x[1][1])).stdev()\n",
    "print mean\n",
    "print std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = 16796.2444516\n",
    "std = 28172.0146034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def round_to(n, precision):\n",
    "    correction = 0.5 if n >= 0 else -0.5\n",
    "    return int( n/precision+correction ) * precision\n",
    "\n",
    "def round_to_05(n):\n",
    "    return round_to(n, 0.05)\n",
    "\n",
    "print round_to_05(18.75698)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ReadyAccessOfferLogs = (extremeCappedAggregAccessOfferLogs\n",
    "                  .map(lambda ((k1,k2),(x,y)) : ((k1,k2), round_to_05((y-mean)/std) ))\n",
    "                  )\n",
    "ReadyAccessOfferLogs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ReadyAccessOfferLogs.take(5)\n",
    "print ReadyCartLogs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ReadyAllLogs = (ReadyAccessOfferLogs\n",
    "                .union(ReadyCartLogs)\n",
    "                .reduceByKey(lambda x,y : x if x > y else y)\n",
    "                .map(lambda ((x,y),z): (x,y,z))\n",
    "                .cache()\n",
    "                )\n",
    "print ReadyAllLogs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainingRDD, validationRDD, testRDD = ReadyAllLogs.randomSplit([6, 2, 2], seed=0L) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Build_Baseline_RDD(refRDD, testRDD):\n",
    "        mu = refRDD.map(lambda x : x[2]).mean()\n",
    "        print mu\n",
    "        userAverageRatings = (refRDD\n",
    "                              .map(lambda x : (x[0],(x[2],1)))\n",
    "                              .reduceByKey(lambda x,y : (x[0]+y[0], x[1]+y[1]))\n",
    "                              .map(lambda (x,(y,z)): (x,(y-mu)/z))\n",
    "                              .collect()\n",
    "                              )\n",
    "\n",
    "        productAverageRatings = (refRDD\n",
    "                              .map(lambda x : (x[1],(x[2],1)))\n",
    "                              .reduceByKey(lambda x,y : (x[0]+y[0], x[1]+y[1]))\n",
    "                              .map(lambda (x,(y,z)): (x,(y-mu)/z))\n",
    "                              .collect()\n",
    "                              )\n",
    "       \n",
    "        userList = dict(userAverageRatings)\n",
    "        productList = dict(productAverageRatings)\n",
    "        \n",
    "        baselineRDD = testRDD.map(lambda (x,y) : (x,y, mu + userList[x]+productList[y]))\n",
    "        \n",
    "        return baselineRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "import math\n",
    "def auditError(predictedRDD, actualRDD):\n",
    "    \n",
    "    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = predictedRDD.map(lambda (x,y,z) : ((x,y),z))\n",
    "\n",
    "    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = actualRDD.map(lambda (x,y,z) : ((x,y),z))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def computeError(predictedRDD, actualRDD):\n",
    "    \"\"\" Compute the root mean squared error between predicted and actual\n",
    "    Args:\n",
    "        predictedRDD: predicted ratings for each movie and each user where each entry is in the form\n",
    "                      (UserID, MovieID, Rating)\n",
    "        actualRDD: actual ratings where each entry is in the form (UserID, MovieID, Rating)\n",
    "    Returns:\n",
    "        RSME (float): computed RSME value\n",
    "    \"\"\"\n",
    "    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = predictedRDD.map(lambda (x,y,z) : ((x,y),z))\n",
    "\n",
    "    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = actualRDD.map(lambda (x,y,z) : ((x,y),z))\n",
    "\n",
    "    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n",
    "    # RDD) in the reformatted RDDs using RDD transformtions - do not use collect()\n",
    "    squaredErrorsRDD = (predictedReformattedRDD\n",
    "                        .join(actualReformattedRDD)\n",
    "                        .map(lambda ((x,y),(a,b)):((x,y),math.pow(a-b,2)) )\n",
    "                       )\n",
    "\n",
    "    # Compute the total squared error - do not use collect()\n",
    "    #totalError = squaredErrorsRDD.reduce(lambda (a,b),(c,d) : b+d)\n",
    "    totalError = squaredErrorsRDD.map(lambda ((x,y),z) : z).sum()\n",
    "\n",
    "    # Count the number of entries for which you computed the total squared error\n",
    "    numRatings = squaredErrorsRDD.count()\n",
    "\n",
    "    # Using the total squared error and the number of entries, compute the RSME\n",
    "    return math.sqrt(totalError/numRatings)\n",
    "\n",
    "\n",
    "# sc.parallelize turns a Python list into a Spark RDD.\n",
    "testPredicted = sc.parallelize([\n",
    "    (1, 1, 5),\n",
    "    (1, 2, 3),\n",
    "    (1, 3, 4),\n",
    "    (2, 1, 3),\n",
    "    (2, 2, 2),\n",
    "    (2, 3, 4)])\n",
    "testActual = sc.parallelize([\n",
    "     (1, 2, 3),\n",
    "     (1, 3, 5),\n",
    "     (2, 1, 5),\n",
    "     (2, 2, 1)])\n",
    "testPredicted2 = sc.parallelize([\n",
    "     (2, 2, 5),\n",
    "     (1, 2, 5)])\n",
    "testError = computeError(testPredicted, testActual)\n",
    "print 'Error for test dataset (should be 1.22474487139): %s' % testError\n",
    "\n",
    "testError2 = computeError(testPredicted2, testActual)\n",
    "print 'Error for test dataset2 (should be 3.16227766017): %s' % testError2\n",
    "\n",
    "testError3 = computeError(testActual, testActual)\n",
    "print 'Error for testActual dataset (should be 0.0): %s' % testError3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "validationForPredictRDD = validationRDD.map(lambda  (x,y,z): (x,y)).cache()\n",
    "\n",
    "seed = 5L\n",
    "iterations = 20\n",
    "regularizationParameter = 0.1\n",
    "ranks = [ 16, 20]\n",
    "errors = [0, 0]\n",
    "err = 0\n",
    "tolerance = 0.03\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "    predictedRatingsRDD = model.predictAll(validationForPredictRDD)\n",
    "    error = computeError(predictedRatingsRDD, validationRDD)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % bestRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylist =  validationRDD.map(lambda x : (x[2],1)).reduceByKey(lambda x,y : x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confront with baseline figures ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselineValidationSetRDD = Build_Baseline_RDD(ReadyAllLogs, validationForPredictRDD)\n",
    "print baselineValidationSetRDD.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRMSE = computeError(validationRDD, baselineValidationSetRDD)\n",
    "print testRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"toto.csv\", 'wb') as f :\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerows(mylist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Lister les profiles utilisateurs par nombre de produits différents consultés ############\n",
    "UserActionProfiles = (ReadyAllLogs\n",
    "                     .map(lambda(x,y,z):(x,1))\n",
    "                     .reduceByKey(lambda x,y : x+y)\n",
    "                     .map(lambda (x,y):(y,1))\n",
    "                     .reduceByKey(lambda x,y : x+y)\n",
    "                     .collect()\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print UserActionProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NotationProfiles = (testRDD\n",
    "                    .map(lambda (x,y,z): (z,1))\n",
    "                    .reduceByKey(lambda x,y : x+y)\n",
    "                    .filter(lambda (x,y):x <= -0.1)\n",
    "                    .takeOrdered(10)\n",
    "\n",
    "                    )\n",
    "print NotationProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "x = np.linspace(0, 3*np.pi, 500)\n",
    "plt.plot(x, np.sin(x**2))\n",
    "plt.title('A simple chirp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "gaussian_numbers = normal(size=1000)\n",
    "plt.hist(gaussian_numbers)\n",
    "plt.title(\"Gaussian Histogram\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "myModel = ALS.train(trainingRDD, 20, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "testForPredictingRDD = testRDD.map(lambda (x,y,z) : (x,y)).cache()\n",
    "predictedTestRDD = myModel.predictAll(testForPredictingRDD)\n",
    "\n",
    "testRMSE = computeError(testRDD, predictedTestRDD)\n",
    "\n",
    "print 'The model had a RMSE on the test set of %s' % testRMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
